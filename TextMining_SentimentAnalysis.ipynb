{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "import os\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import nltk \n",
    "import textmining\n",
    "import matplotlib.pyplot as plt\n",
    "#from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set working directory\n",
    "os.chdir(\"G:\\Analytics\\Edwisor\\Case Study\\Text Mining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Text data\n",
    "post = pd.read_csv(\"Post.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select few text\n",
    "post = post.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Repository\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract stop words\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Remove punctuation marks\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text pre processing\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = \" \".join([ch for ch in stop_free.lower().split() if ch not in exclude])\n",
    "    num_free = \" \".join(i for i in punc_free if not i.isdigit())\n",
    "    return num_free\n",
    "\n",
    "post_corpus = [clean(post.iloc[i,1]) for i in range(0, post.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create document term matrix\n",
    "tdm = textmining.TermDocumentMatrix()\n",
    "\n",
    "for i in post_corpus:\n",
    "    \n",
    "    tdm.add_doc(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write tdm\n",
    "tdm.write_csv(\"TDM_DataFRame.csv\", cutoff = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataframe for analysis\n",
    "df = pd.read_csv(\"TDM_DataFRame.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot wordcloud\n",
    "wordcloud = WordCloud(width = 1000, hieght = 500, stopwords = STOPWORDS, background_color = 'white').generate(\n",
    "                        ''.join(post['Post']))\n",
    "\n",
    "plt.figure(figsize = (15,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sentiment analysis using Text Blob\n",
    "# Create empty dataframe to store results\n",
    "FinalResults = pd.DataFrame()\n",
    "\n",
    "# Run Engine\n",
    "for i in range(0, post.shape[0]):\n",
    "    \n",
    "    blob = TextBlob(post.iloc[i,1])\n",
    "    \n",
    "    temp = pd.DataFrame({'Comments': post.iloc[i,1], 'Polarity': blob.sentiment.polarity}, index = [0])\n",
    "    \n",
    "    FinalResults = FinalResults.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis using Vader\n",
    "FinalResults_Vader = pd.DataFrame()\n",
    "\n",
    "# Create engine\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Run Engine\n",
    "for i in range(0, post.shape[0]):\n",
    "    \n",
    "    snt = analyzer.polarity_scores(post.iloc[i,1])\n",
    "    \n",
    "    temp = pd.DataFrame({'Comments': post.iloc[i,1], 'Polarity': list(snt.items())[3][1]}, index = [0])\n",
    "\n",
    "    FinalResults_Vader = FinalResults_Vader.append(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
